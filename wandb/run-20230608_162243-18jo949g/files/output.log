











































































































































































































































































































































































  8%|█████████████                                                                                                                                                           | 19469/250000 [13:25<2:38:53, 24.18it/s]
Traceback (most recent call last):
  File "c:\Users\janwe\OneDrive\Desktop\Master_Thesis\Other projects\moral_rl\moral\ppo_train.py", line 63, in <module>
    update_policy(ppo, dataset, optimizer, config.gamma, config.epsilon, config.ppo_epochs,
  File "c:\Users\janwe\OneDrive\Desktop\Master_Thesis\Other projects\moral_rl\moral\ppo.py", line 139, in update_policy
    action_log_probabilities, critic_values, action_entropy = ppo.evaluate_trajectory(tau)
  File "c:\Users\janwe\OneDrive\Desktop\Master_Thesis\Other projects\moral_rl\moral\ppo.py", line 65, in evaluate_trajectory
    action_probabilities, critic_values = self.forward(trajectory_states)
  File "c:\Users\janwe\OneDrive\Desktop\Master_Thesis\Other projects\moral_rl\moral\ppo.py", line 33, in forward
    x_actor = self.relu(self.actor_l3(x))
  File "C:\Users\janwe\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\janwe\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\conv.py", line 443, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "C:\Users\janwe\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\nn\modules\conv.py", line 439, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
KeyboardInterrupt