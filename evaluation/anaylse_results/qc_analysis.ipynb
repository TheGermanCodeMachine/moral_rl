{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', '..'))\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from tabulate import tabulate\n",
    "from helpers.util_functions import normalise_value\n",
    "\n",
    "from moral.ppo import PPO, TrajectoryDataset, update_policy\n",
    "from envs.gym_wrapper import *\n",
    "import random\n",
    "\n",
    "from quality_metrics.validity_measures import validity_all as validity\n",
    "from quality_metrics.validity_measures import validity_single, validity_single_partial\n",
    "from quality_metrics.distance_measures import distance_all as distance\n",
    "from quality_metrics.distance_measures import distance_single\n",
    "from quality_metrics.diversity_measures import diversity_all as diversity\n",
    "from quality_metrics.diversity_measures import diversity_single, distance_subtrajectories\n",
    "from quality_metrics.critical_state_measures import critical_state_all as critical_state\n",
    "from quality_metrics.critical_state_measures import critical_state_single\n",
    "from quality_metrics.realisticness_measures import realisticness_all as realisticness\n",
    "from quality_metrics.realisticness_measures import realisticness_single_partial\n",
    "from quality_metrics.sparsity_measure import sparsity_all as sparsity\n",
    "from quality_metrics.sparsity_measure import sparsitiy_single_partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing quality criterias\n",
    "\n",
    "I will visualize the distribution of quality criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    env_id= 'randomized_v2'\n",
    "    env_steps= 8e6\n",
    "    batchsize_ppo= 12\n",
    "    n_queries= 50\n",
    "    preference_noise= 0\n",
    "    n_workers= 1\n",
    "    lr_ppo= 3e-4\n",
    "    entropy_reg= 0.25\n",
    "    gamma= 0.999\n",
    "    epsilon= 0.1\n",
    "    ppo_epochs= 5\n",
    "    max_steps = 75\n",
    "    base_path = '.\\datasets\\\\100mstep\\\\'\n",
    "    measure_statistics = True\n",
    "    num_runs = 100\n",
    "    criteria = ['validity', 'diversity', 'proximity', 'critical_state', 'realisticness', 'sparsity']\n",
    "    # criteria = ['baseline']\n",
    "    # criteria = ['validity']\n",
    "    cf_method = 'step' # 'mcts' or 'step'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the trajectories\n",
    "with open('..\\..\\datasets\\\\100mcts\\\\100\\cf_trajectories.pkl', 'rb') as f:\n",
    "    cf_mcts = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100mcts\\\\100\\org_trajectories.pkl', 'rb') as f:\n",
    "    org_mcts = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100mcts\\\\100\\statistics\\start_points.pkl', 'rb') as f:\n",
    "    starts_mcts = pkl.load(f)\n",
    "\n",
    "with open('..\\..\\datasets\\\\100step\\\\100\\cf_trajectories.pkl', 'rb') as f:\n",
    "    cf_step = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100step\\\\100\\org_trajectories.pkl', 'rb') as f:\n",
    "    org_step = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100step\\\\100\\statistics\\start_points.pkl', 'rb') as f:\n",
    "    starts_step = pkl.load(f)\n",
    "\n",
    "with open('..\\..\\datasets\\\\100random\\\\100\\cf_trajectories.pkl', 'rb') as f:\n",
    "    cf_random = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100random\\\\100\\org_trajectories.pkl', 'rb') as f:\n",
    "    org_random = pkl.load(f)\n",
    "with open('..\\..\\datasets\\\\100random\\\\100\\statistics\\start_points.pkl', 'rb') as f:\n",
    "    starts_random = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load normalisation\n",
    "\n",
    "with open('..\\..\\interpretability\\\\normalisation_values.pkl', 'rb') as f:\n",
    "    normalisation = pkl.load(f)\n",
    "\n",
    "weight = {'validity': 1, 'proximity': 1, 'critical_state': 0.5, 'diversity': 0.5, 'realisticness': 0.2, 'sparsity': 0.5}\n",
    "\n",
    "random.seed(4)\n",
    "seed_env = random.randint(0, 100000)\n",
    "torch.manual_seed(seed_env)\n",
    "np.random.seed(seed_env)\n",
    "\n",
    "# Create Environment\n",
    "vec_env = VecEnv(config.env_id, config.n_workers, seed=seed_env)\n",
    "states = vec_env.reset()\n",
    "states_tensor = torch.tensor(states).float().to(device)\n",
    "\n",
    "# Fetch Shapes\n",
    "n_actions = vec_env.action_space.n\n",
    "obs_shape = vec_env.observation_space.shape\n",
    "state_shape = obs_shape[:-1]\n",
    "in_channels = obs_shape[-1]\n",
    "\n",
    "ppo = PPO(state_shape=state_shape, in_channels=in_channels, n_actions=n_actions).to(device)\n",
    "ppo.load_state_dict(torch.load('..\\..\\saved_models/ppo_airl_v2_[1,10].pt', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcts_val, mcts_prox, mcts_div, mcts_crit, mcts_spar, mcts_real, mcts_qc = [], [], [], [], [], [], []\n",
    "prev_org_trajs, prev_cf_trajs, prev_starts = [], [], []\n",
    "\n",
    "for i in range(100):\n",
    "    val = validity_single_partial(org_mcts[i][0], cf_mcts[i][0])\n",
    "    val = normalise_value(val, normalisation, 'validity') * weight['validity']\n",
    "    mcts_val.append(val)\n",
    "    prox = distance_subtrajectories(org_mcts[i][0], cf_mcts[i][0])\n",
    "    prox = normalise_value(prox, normalisation, 'proximity') * weight['proximity']\n",
    "    mcts_prox.append(prox)\n",
    "    div = diversity_single(org_mcts[i][0], cf_mcts[i][0], starts_mcts[i], prev_org_trajs, prev_cf_trajs, prev_starts)\n",
    "    div = normalise_value(div, normalisation, 'diversity') * weight['diversity']\n",
    "    mcts_div.append(div)\n",
    "    crit = critical_state_single(ppo, org_mcts[i][0]['states'][0])\n",
    "    crit = normalise_value(crit, normalisation, 'critical_state') * weight['critical_state']\n",
    "    mcts_crit.append(crit)\n",
    "    spar = sparsitiy_single_partial(org_mcts[i][0], cf_mcts[i][0])\n",
    "    spar = normalise_value(spar, normalisation, 'sparsity') * weight['sparsity']\n",
    "    mcts_spar.append(spar)\n",
    "    real = realisticness_single_partial(org_mcts[i][0], cf_mcts[i][0])\n",
    "    real = normalise_value(real, normalisation, 'realisticness') * weight['realisticness']\n",
    "    mcts_real.append(real)\n",
    "    qc = val + prox + div + crit + spar + real\n",
    "    mcts_qc.append(qc)\n",
    "\n",
    "    prev_org_trajs.append(org_mcts[i][0])\n",
    "    prev_cf_trajs.append(cf_mcts[i][0])\n",
    "    prev_starts.append(starts_mcts[i])\n",
    "\n",
    "step_val, step_prox, step_div, step_crit, step_spar, step_real, step_qc = [], [], [], [], [], [], []\n",
    "prev_org_trajs, prev_cf_trajs, prev_starts = [], [], []\n",
    "\n",
    "for i in range(100):\n",
    "    val = validity_single_partial(org_step[i][0], cf_step[i][0])\n",
    "    val = normalise_value(val, normalisation, 'validity') * weight['validity']\n",
    "    step_val.append(val)\n",
    "    prox = distance_subtrajectories(org_step[i][0], cf_step[i][0])\n",
    "    prox = normalise_value(prox, normalisation, 'proximity') * weight['proximity']\n",
    "    step_prox.append(prox)\n",
    "    div = diversity_single(org_step[i][0], cf_step[i][0], starts_step[i], prev_org_trajs, prev_cf_trajs, prev_starts)\n",
    "    div = normalise_value(div, normalisation, 'diversity') * weight['diversity']\n",
    "    step_div.append(div)\n",
    "    crit = critical_state_single(ppo, org_step[i][0]['states'][0])\n",
    "    crit = normalise_value(crit, normalisation, 'critical_state') * weight['critical_state']\n",
    "    step_crit.append(crit)\n",
    "    spar = sparsitiy_single_partial(org_step[i][0], cf_step[i][0])\n",
    "    spar = normalise_value(spar, normalisation, 'sparsity') * weight['sparsity']\n",
    "    step_spar.append(spar)\n",
    "    \n",
    "    real = realisticness_single_partial(org_step[i][0], cf_step[i][0])\n",
    "    real = normalise_value(real, normalisation, 'realisticness') * weight['realisticness']\n",
    "    if real > 10:\n",
    "        real =2\n",
    "    step_real.append(real)\n",
    "    qc = val + prox + div + crit + spar + real\n",
    "    step_qc.append(qc)\n",
    "\n",
    "    prev_org_trajs.append(org_step[i][0])\n",
    "    prev_cf_trajs.append(cf_step[i][0])\n",
    "    prev_starts.append(starts_step[i])\n",
    "\n",
    "random_val, random_prox, random_div, random_crit, random_spar, random_real, random_qc = [], [], [], [], [], [], []\n",
    "prev_org_trajs, prev_cf_trajs, prev_starts = [], [], []\n",
    "\n",
    "for i in range(100):\n",
    "    val = validity_single_partial(org_random[i][0], cf_random[i][0])\n",
    "    val = normalise_value(val, normalisation, 'validity') * weight['validity']\n",
    "    random_val.append(val)\n",
    "    prox = distance_subtrajectories(org_random[i][0], cf_random[i][0])\n",
    "    prox = normalise_value(prox, normalisation, 'proximity') * weight['proximity']\n",
    "    random_prox.append(prox)\n",
    "    div = diversity_single(org_random[i][0], cf_random[i][0], starts_random[i], prev_org_trajs, prev_cf_trajs, prev_starts)\n",
    "    div = normalise_value(div, normalisation, 'diversity') * weight['diversity']\n",
    "    random_div.append(div)\n",
    "    crit = critical_state_single(ppo, org_random[i][0]['states'][0])\n",
    "    crit = normalise_value(crit, normalisation, 'critical_state') * weight['critical_state']\n",
    "    random_crit.append(crit)\n",
    "    spar = sparsitiy_single_partial(org_random[i][0], cf_random[i][0])\n",
    "    spar = normalise_value(spar, normalisation, 'sparsity') * weight['sparsity']\n",
    "    random_spar.append(spar)\n",
    "    real = realisticness_single_partial(org_random[i][0], cf_random[i][0])\n",
    "    real = normalise_value(real, normalisation, 'realisticness') * weight['realisticness']\n",
    "    random_real.append(real)\n",
    "    qc = val + prox + div + crit + spar + real\n",
    "    random_qc.append(qc)\n",
    "\n",
    "    prev_org_trajs.append(org_random[i][0])\n",
    "    prev_cf_trajs.append(cf_random[i][0])\n",
    "    prev_starts.append(starts_random[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics      mcts mean    mcts std    step mean    step std    random mean    random std\n",
      "------------  -----------  ----------  -----------  ----------  -------------  ------------\n",
      "validity             0.42        0.35         0.28        0.25           0.12          0.14\n",
      "proximity            0.61        0.34         0.2         0.18           0.3           0.33\n",
      "diversity            0.09        0.07         0.09        0.1            0.15          0.08\n",
      "critical             0.4         0.06         0.38        0.12           0.09          0.11\n",
      "realistic            0.1         0.21         0.14        0.4            0.07          0.22\n",
      "sparsity             0.34        0.17         0.37        0.51          -0.08          0.47\n",
      "qc                   1.97        0.61         1.46        0.52           0.65          0.62\n",
      "63\n",
      "2.1852457843640667 -0.036523552828322134\n",
      "2.0904233085805326 -0.0014312605748282774\n",
      "1.7722453596776881 -0.25298832088027157\n"
     ]
    }
   ],
   "source": [
    "# print the average and standard deviation of the statistics\n",
    "table = [\n",
    "    ['statistics'] + ['mcts mean'] + ['mcts std'] + ['step mean'] + ['step std'] + ['random mean'] + ['random std'],\n",
    "    ['validity'] + [round(np.mean(mcts_val), 2), round(np.std(mcts_val), 2)] + [round(np.mean(step_val), 2), round(np.std(step_val), 2)] + [round(np.mean(random_val), 2), round(np.std(random_val), 2)],\n",
    "    ['proximity'] + [round(np.mean(mcts_prox), 2), round(np.std(mcts_prox), 2)] + [round(np.mean(step_prox), 2), round(np.std(step_prox), 2)] + [round(np.mean(random_prox), 2), round(np.std(random_prox), 2)],\n",
    "    ['diversity'] + [round(np.mean(mcts_div), 2), round(np.std(mcts_div), 2)] + [round(np.mean(step_div), 2), round(np.std(step_div), 2)] + [round(np.mean(random_div), 2), round(np.std(random_div), 2)],\n",
    "    ['critical'] + [round(np.mean(mcts_crit), 2), round(np.std(mcts_crit), 2)] + [round(np.mean(step_crit), 2), round(np.std(step_crit), 2)] + [round(np.mean(random_crit), 2), round(np.std(random_crit), 2)],\n",
    "    ['realistic'] + [round(np.mean(mcts_real), 2), round(np.std(mcts_real), 2)] + [round(np.mean(step_real), 2), round(np.std(step_real), 2)] + [round(np.mean(random_real), 2), round(np.std(random_real), 2)],\n",
    "    ['sparsity'] + [round(np.mean(mcts_spar), 2), round(np.std(mcts_spar), 2)] + [round(np.mean(step_spar), 2), round(np.std(step_spar), 2)] + [round(np.mean(random_spar), 2), round(np.std(random_spar), 2)],\n",
    "    ['qc'] + [round(np.mean(mcts_qc), 2), round(np.std(mcts_qc), 2)] + [round(np.mean(step_qc), 2), round(np.std(step_qc), 2)] + [round(np.mean(random_qc), 2), round(np.std(random_qc), 2)]\n",
    "]\n",
    "\n",
    "print(tabulate(table, headers='firstrow'))\n",
    "# index of the highest qc_step\n",
    "print(step_real.index(max(step_real)))\n",
    "print(max(step_real), min(step_real))\n",
    "print(max(mcts_real), min(mcts_real))\n",
    "print(max(random_real), min(random_real))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the quality criteria\n",
    "\n",
    "criteria = ['validity', 'proximity', 'diversity', 'critical', 'realistic', 'sparsity', 'qc']\n",
    "\n",
    "mcts_means = [np.mean(mcts_val), np.mean(mcts_prox), np.mean(mcts_div), np.mean(mcts_crit), np.mean(mcts_real), np.mean(mcts_spar), np.mean(qc_mcts)]\n",
    "mcts_upper = [np.percentile(mcts_val, 75), np.percentile(mcts_prox, 75), np.percentile(mcts_div, 75), np.percentile(mcts_crit, 75), np.percentile(mcts_real, 75), np.percentile(mcts_spar, 75), np.percentile(qc_mcts, 75)]\n",
    "mcts_lower = [np.percentile(mcts_val, 25), np.percentile(mcts_prox, 25), np.percentile(mcts_div, 25), np.percentile(mcts_crit, 25), np.percentile(mcts_real, 25), np.percentile(mcts_spar, 25), np.percentile(qc_mcts, 25)]\n",
    "\n",
    "step_means = [np.mean(step_val), np.mean(step_prox), np.mean(step_div), np.mean(step_crit), np.mean(step_real), np.mean(step_spar), np.mean(qc_step)]\n",
    "step_upper = [np.percentile(step_val, 75), np.percentile(step_prox, 75), np.percentile(step_div, 75), np.percentile(step_crit, 75), np.percentile(step_real, 75), np.percentile(step_spar, 75), np.percentile(qc_step, 75)]\n",
    "step_lower = [np.percentile(step_val, 25), np.percentile(step_prox, 25), np.percentile(step_div, 25), np.percentile(step_crit, 25), np.percentile(step_real, 25), np.percentile(step_spar, 25), np.percentile(qc_step, 25)]\n",
    "\n",
    "random_means = [np.mean(random_val), np.mean(random_prox), np.mean(random_div), np.mean(random_crit), np.mean(random_real), np.mean(random_spar), np.mean(qc_random)]\n",
    "random_upper = [np.percentile(random_val, 75), np.percentile(random_prox, 75), np.percentile(random_div, 75), np.percentile(random_crit, 75), np.percentile(random_real, 75), np.percentile(random_spar, 75), np.percentile(qc_random, 75)]\n",
    "random_lower = [np.percentile(random_val, 25), np.percentile(random_prox, 25), np.percentile(random_div, 25), np.percentile(random_crit, 25), np.percentile(random_real, 25), np.percentile(random_spar, 25), np.percentile(qc_random, 25)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(criteria))\n",
    "width = 0.3\n",
    "\n",
    "rects1 = ax.bar(x - width, mcts_means, width, label='MCTS', yerr=[np.subtract(mcts_means, mcts_lower), np.subtract(mcts_upper, mcts_means)], capsize=5)\n",
    "rects2 = ax.bar(x, step_means, width, label='1-step deviation', yerr=[np.subtract(step_means, step_lower), np.subtract(step_upper, step_means)], capsize=5)\n",
    "rects3 = ax.bar(x + width, random_means, width, label='Random', yerr=[np.subtract(random_means, random_lower), np.subtract(random_upper, random_means)], capsize=5)\n",
    "\n",
    "ax.set_ylabel('Normalised value of criteria')\n",
    "ax.set_title('Quality criteria')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(criteria)\n",
    "ax.legend()\n",
    "\n",
    "# plt.errorbar(x, mcts_means, yerr=[np.subtract(mcts_means, mcts_lower), np.subtract(mcts_upper, mcts_means)], fmt='none', ecolor='black', capsize=5)\n",
    "# plt.errorbar(x, step_means, yerr=[np.subtract(step_means, step_lower), np.subtract(step_upper, step_means)], fmt='none', ecolor='black', capsize=5)\n",
    "# plt.errorbar(x, random_means, yerr=[np.subtract(random_means, random_lower), np.subtract(random_upper, random_means)], fmt='none', ecolor='black', capsize=5)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = [\n",
    "    ['criteria'] + ['validity'] + ['proximity'] + ['diversity'] + ['critical'] + ['realistic'] + ['sparsity'] + ['qc'],\n",
    "    ['validity'] + [1] + [round(pearsonr(mcts_val, mcts_prox)[0],2)] + [round(pearsonr(mcts_val, mcts_div)[0],2)] + [round(pearsonr(mcts_val, mcts_crit)[0],2)] + [round(pearsonr(mcts_val, mcts_real)[0],2)] + [round(pearsonr(mcts_val, mcts_spar)[0],2)] + [round(pearsonr(mcts_val, qc_mcts)[0],2)],\n",
    "    ['proximity'] + [round(pearsonr(mcts_prox, mcts_val)[0],2)] + [1] + [round(pearsonr(mcts_prox, mcts_div)[0],2)] + [round(pearsonr(mcts_prox, mcts_crit)[0],2)] + [round(pearsonr(mcts_prox, mcts_real)[0],2)] + [round(pearsonr(mcts_prox, mcts_spar)[0],2)] + [round(pearsonr(mcts_prox, qc_mcts)[0],2)],\n",
    "    ['diversity'] + [round(pearsonr(mcts_div, mcts_val)[0],2)] + [round(pearsonr(mcts_div, mcts_prox)[0],2)] + [1] + [round(pearsonr(mcts_div, mcts_crit)[0],2)] + [round(pearsonr(mcts_div, mcts_real)[0],2)] + [round(pearsonr(mcts_div, mcts_spar)[0],2)] + [round(pearsonr(mcts_div, qc_mcts)[0],2)],\n",
    "    ['critical'] + [round(pearsonr(mcts_crit, mcts_val)[0],2)] + [round(pearsonr(mcts_crit, mcts_prox)[0],2)] + [round(pearsonr(mcts_crit, mcts_div)[0],2)] + [1] + [round(pearsonr(mcts_crit, mcts_real)[0],2)] + [round(pearsonr(mcts_crit, mcts_spar)[0],2)] + [round(pearsonr(mcts_crit, qc_mcts)[0],2)],\n",
    "    ['realistic'] + [round(pearsonr(mcts_real, mcts_val)[0],2)] + [round(pearsonr(mcts_real, mcts_prox)[0],2)] + [round(pearsonr(mcts_real, mcts_div)[0],2)] + [round(pearsonr(mcts_real, mcts_crit)[0],2)] + [1] + [round(pearsonr(mcts_real, mcts_spar)[0],2)] + [round(pearsonr(mcts_real, qc_mcts)[0],2)],\n",
    "    ['sparsity'] + [round(pearsonr(mcts_spar, mcts_val)[0],2)] + [round(pearsonr(mcts_spar, mcts_prox)[0],2)] + [round(pearsonr(mcts_spar, mcts_div)[0],2)] + [round(pearsonr(mcts_spar, mcts_crit)[0],2)] + [round(pearsonr(mcts_spar, mcts_real)[0],2)] + [1] + [round(pearsonr(mcts_spar, qc_mcts)[0],2)],\n",
    "    ['qc'] + [round(pearsonr(qc_mcts, mcts_val)[0],2)] + [round(pearsonr(qc_mcts, mcts_prox)[0],2)] + [round(pearsonr(qc_mcts, mcts_div)[0],2)] + [round(pearsonr(qc_mcts, mcts_crit)[0],2)] + [round(pearsonr(qc_mcts, mcts_real)[0],2)] + [round(pearsonr(qc_mcts, mcts_spar)[0],2)] + [1] \n",
    "]\n",
    "\n",
    "# print as latex table\n",
    "print(tabulate(table, headers='firstrow', tablefmt='latex'))\n",
    "print(tabulate(table, headers='firstrow'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
